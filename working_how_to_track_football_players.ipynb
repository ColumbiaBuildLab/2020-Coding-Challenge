{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaylchetty/2020-Coding-Challenge/blob/master/working_how_to_track_football_players.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy7oLR8SHozt"
      },
      "source": [
        "# Football players tracking with YOLOv5 + ByteTrack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV9XIIPnI4GV"
      },
      "source": [
        "## About\n",
        "\n",
        "In this tutorial, we will utilize an open source computer vision dataset from one of the 100,000+ available on [Roboflow Universe](https://universe.roboflow.com/).\n",
        "\n",
        "If you already have your own images (and, optionally, annotations), you can convert your dataset using Roboflow, a set of tools developers use to build better computer vision models quickly and accurately. 150k+ developers use roboflow for (automatic) annotation, converting dataset formats (like to YOLOv5), training, deploying, and improving their datasets/models.\n",
        "\n",
        "**Usefull links:**\n",
        "\n",
        "- [YOLOv5 repository](https://github.com/ultralytics/yolov5)\n",
        "- [ByteTrack repository](https://github.com/ifzhang/ByteTrack)\n",
        "- [Roboflow Notebooks](https://github.com/roboflow-ai/notebooks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTZ_cli2khiK"
      },
      "source": [
        "## Table of content:\n",
        "* [Setup](#setup)\n",
        "* [Download data](#download-data)\n",
        "* [Install YOLOv5](#install-yolov5)\n",
        "* [Install ByteTrack and other libs](#install-bytetrack)\n",
        "* [Custom annotator](#custom-annotator)\n",
        "* [Detect ball possession](#detect-ball-possession)\n",
        "* [Full video tracking](#full-video-tracking)\n",
        "* [Put everything together](#put-everything-together)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWHbifsXJBR9"
      },
      "source": [
        "## Setup <a class=\"anchor\" id=\"setup\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jr40IbZwjQSv"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5mqUgm7MkvY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aup18ZYsJNtm"
      },
      "source": [
        "## Download data <a class=\"anchor\" id=\"download-data\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZxfTw7UIvR5"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle --upgrade --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnEI9XuAJQFd"
      },
      "source": [
        "We will use [DFL - Bundesliga Data Shootout](https://www.kaggle.com/competitions/dfl-bundesliga-data-shootout/data) from Kaggle. We can download it using [Kaggle API](https://github.com/Kaggle/kaggle-api). According to documentation we need to set up two environment variables first:\n",
        "\n",
        "```\n",
        "export KAGGLE_USERNAME=datadinosaur\n",
        "export KAGGLE_KEY=xxxxxxxxxxxxxx\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebh3CnjdH3xy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5su9nb7LuSy"
      },
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_USERNAME'] = 'shaylchetty'\n",
        "os.environ['KAGGLE_KEY'] = 'b7b80ac1136b32baa81e1abe5502b2a5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktm8j2MVxcHh"
      },
      "outputs": [],
      "source": [
        "# !kaggle competitions files -c dfl-bundesliga-data-shootout | grep clips | head -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7_SA2kwOWwY"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "!kaggle competitions files -c dfl-bundesliga-data-shootout | \\\n",
        "grep clips | head -20 | \\\n",
        "awk '{print $1}' | \\\n",
        "while read -r line; \\\n",
        "  do kaggle competitions download -c dfl-bundesliga-data-shootout -f $line -p clips --quiet; \\\n",
        "  unzip ${line}.zip -d clips && rm ${line}.zip; \\\n",
        "  done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oips7RZW1xTH"
      },
      "source": [
        "## Install YOLOv5 <a class=\"anchor\" id=\"install-yolov5\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_uyfMaeyOtY"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -r requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-SYMcsovOi1"
      },
      "source": [
        "### Use pre-trained COCO model - full video"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd {HOME}/yolov5\n",
        "# !python detect.py --weights yolov5x.pt --img 640 --conf 0.25 --source {HOME}/clips/08fd33_4.mp4 --name coco"
      ],
      "metadata": {
        "id": "urud0xNHp_MY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t203cKOuo-rk"
      },
      "outputs": [],
      "source": [
        "# %cd {HOME}/yolov5\n",
        "# !python detect.py --weights yolov5x6.pt --img 1280 --conf 0.25 --source {HOME}/clips/08fd33_4.mp4 --name coco"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAcp8zXKznYU"
      },
      "source": [
        "### Use custom model - full video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GiPuc8tzraN"
      },
      "source": [
        "This model was traind using [football-players-detection](https://app.roboflow.com/roboflow-jvuqo/football-players-detection-3zvbc/overview) dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1OYwrlRti4cieuvVr8ERaJhTQdFJXWT4I' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1OYwrlRti4cieuvVr8ERaJhTQdFJXWT4I\" -O best.pt && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "id": "hdpfRYRTLVPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WEIGHTS_PATH = f\"{HOME}/best.pt\""
      ],
      "metadata": {
        "id": "VMkxmV60AMVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxDHLHGFunhT"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}/yolov5\n",
        "!python detect.py --weights {HOME}/best.pt --img 1280 --conf 0.25 --source {HOME}/clips/08fd33_4.mp4 --name custom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OZTnYzu5orw"
      },
      "source": [
        "### Use custom model - single frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rs1BDwkZ8VLj"
      },
      "outputs": [],
      "source": [
        "from typing import Generator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "def generate_frames(video_file: str) -> Generator[np.ndarray, None, None]:\n",
        "    video = cv2.VideoCapture(video_file)\n",
        "\n",
        "    while video.isOpened():\n",
        "        success, frame = video.read()\n",
        "\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        yield frame\n",
        "\n",
        "    video.release()\n",
        "\n",
        "\n",
        "def plot_image(image: np.ndarray, size: int = 12) -> None:\n",
        "    plt.figure(figsize=(size, size))\n",
        "    plt.imshow(image[...,::-1])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOURCE_VIDEO_PATH = f\"{HOME}/clips/08fd33_4.mp4\""
      ],
      "metadata": {
        "id": "zzS1LNLP_2hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VgeYUSO-psT"
      },
      "outputs": [],
      "source": [
        "frame_iterator = iter(generate_frames(video_file=SOURCE_VIDEO_PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PD2yC0Zo-1D3"
      },
      "outputs": [],
      "source": [
        "frame = next(frame_iterator)\n",
        "plot_image(frame, 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1zx2sjBlVAR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', WEIGHTS_PATH, device=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_7bMz7w_5n8"
      },
      "outputs": [],
      "source": [
        "results = model(frame, size=1280)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwBstOcrJ5Dd"
      },
      "outputs": [],
      "source": [
        "results.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQ_sw-CYJY7t"
      },
      "outputs": [],
      "source": [
        "results.pred[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlUAtzilKInl"
      },
      "outputs": [],
      "source": [
        "model.names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn2X9aziCS9q"
      },
      "source": [
        "## Install ByteTrack and other libs<a class=\"anchor\" id=\"install-bytetrack\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ByteTrack is great tracker but a bit poorly packaged. We need to jump through some fire hoops to make it work in tandem with YOLOv5.  "
      ],
      "metadata": {
        "id": "w2vHghUslzVj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tiOHf9_Awzj"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/ifzhang/ByteTrack.git\n",
        "!cd ByteTrack && pip3 install -r requirements.txt\n",
        "!cd ByteTrack && python3 setup.py develop\n",
        "!pip install cython_bbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEIUi5qpEMeN"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(f\"{HOME}/ByteTrack\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onemetric --quiet"
      ],
      "metadata": {
        "id": "Wg8EL1ihJ-ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07HKQl6JH21E"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class BYTETrackerArgs:\n",
        "    track_thresh: float = 0.25\n",
        "    track_buffer: int = 30\n",
        "    match_thresh: float = 0.8\n",
        "    aspect_ratio_thresh: float = 3.0\n",
        "    min_box_area: float = 1.0\n",
        "    mot20: bool = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install loguru\n",
        "!pip install lap"
      ],
      "metadata": {
        "id": "roqACh65ssw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
        "from onemetric.cv.utils.iou import box_iou_batch"
      ],
      "metadata": {
        "id": "c2rMgGK8KS5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "933IWoV3FHfF"
      },
      "source": [
        "## Custom annotator <a class=\"anchor\" id=\"custom-annotator\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBcLq7VSEJPx"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Tuple, Optional, List, Dict, Any\n",
        "\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# geometry utilities\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class Point:\n",
        "    x: float\n",
        "    y: float\n",
        "\n",
        "    @property\n",
        "    def int_xy_tuple(self) -> Tuple[int, int]:\n",
        "        return int(self.x), int(self.y)\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class Rect:\n",
        "    x: float\n",
        "    y: float\n",
        "    width: float\n",
        "    height: float\n",
        "\n",
        "    @property\n",
        "    def min_x(self) -> float:\n",
        "        return self.x\n",
        "\n",
        "    @property\n",
        "    def min_y(self) -> float:\n",
        "        return self.y\n",
        "\n",
        "    @property\n",
        "    def max_x(self) -> float:\n",
        "        return self.x + self.width\n",
        "\n",
        "    @property\n",
        "    def max_y(self) -> float:\n",
        "        return self.y + self.height\n",
        "\n",
        "    @property\n",
        "    def top_left(self) -> Point:\n",
        "        return Point(x=self.x, y=self.y)\n",
        "\n",
        "    @property\n",
        "    def bottom_right(self) -> Point:\n",
        "        return Point(x=self.x + self.width, y=self.y + self.height)\n",
        "\n",
        "    @property\n",
        "    def bottom_center(self) -> Point:\n",
        "        return Point(x=self.x + self.width / 2, y=self.y + self.height)\n",
        "\n",
        "    @property\n",
        "    def top_center(self) -> Point:\n",
        "        return Point(x=self.x + self.width / 2, y=self.y)\n",
        "\n",
        "    @property\n",
        "    def center(self) -> Point:\n",
        "        return Point(x=self.x + self.width / 2, y=self.y + self.height / 2)\n",
        "\n",
        "    def pad(self, padding: float) -> Rect:\n",
        "        return Rect(\n",
        "            x=self.x - padding,\n",
        "            y=self.y - padding,\n",
        "            width=self.width + 2*padding,\n",
        "            height=self.height + 2*padding\n",
        "        )\n",
        "\n",
        "    def contains_point(self, point: Point) -> bool:\n",
        "        return self.min_x < point.x < self.max_x and self.min_y < point.y < self.max_y\n",
        "\n",
        "\n",
        "# detection utilities\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Detection:\n",
        "    rect: Rect\n",
        "    class_id: int\n",
        "    class_name: str\n",
        "    confidence: float\n",
        "    tracker_id: Optional[int] = None\n",
        "\n",
        "    @classmethod\n",
        "    def from_results(cls, pred: np.ndarray, names: Dict[int, str]) -> List[Detection]:\n",
        "        result = []\n",
        "        for x_min, y_min, x_max, y_max, confidence, class_id in pred:\n",
        "            class_id=int(class_id)\n",
        "            result.append(Detection(\n",
        "                rect=Rect(\n",
        "                    x=float(x_min),\n",
        "                    y=float(y_min),\n",
        "                    width=float(x_max - x_min),\n",
        "                    height=float(y_max - y_min)\n",
        "                ),\n",
        "                class_id=class_id,\n",
        "                class_name=names[class_id],\n",
        "                confidence=float(confidence)\n",
        "            ))\n",
        "        return result\n",
        "\n",
        "\n",
        "def filter_detections_by_class(detections: List[Detection], class_name: str) -> List[Detection]:\n",
        "    return [\n",
        "        detection\n",
        "        for detection\n",
        "        in detections\n",
        "        if detection.class_name == class_name\n",
        "    ]\n",
        "\n",
        "\n",
        "# draw utilities\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class Color:\n",
        "    r: int\n",
        "    g: int\n",
        "    b: int\n",
        "\n",
        "    @property\n",
        "    def bgr_tuple(self) -> Tuple[int, int, int]:\n",
        "        return self.b, self.g, self.r\n",
        "\n",
        "    @classmethod\n",
        "    def from_hex_string(cls, hex_string: str) -> Color:\n",
        "        r, g, b = tuple(int(hex_string[1 + i:1 + i + 2], 16) for i in (0, 2, 4))\n",
        "        return Color(r=r, g=g, b=b)\n",
        "\n",
        "\n",
        "def draw_rect(image: np.ndarray, rect: Rect, color: Color, thickness: int = 2) -> np.ndarray:\n",
        "    cv2.rectangle(image, rect.top_left.int_xy_tuple, rect.bottom_right.int_xy_tuple, color.bgr_tuple, thickness)\n",
        "    return image\n",
        "\n",
        "\n",
        "def draw_filled_rect(image: np.ndarray, rect: Rect, color: Color) -> np.ndarray:\n",
        "    cv2.rectangle(image, rect.top_left.int_xy_tuple, rect.bottom_right.int_xy_tuple, color.bgr_tuple, -1)\n",
        "    return image\n",
        "\n",
        "\n",
        "def draw_polygon(image: np.ndarray, countour: np.ndarray, color: Color, thickness: int = 2) -> np.ndarray:\n",
        "    cv2.drawContours(image, [countour], 0, color.bgr_tuple, thickness)\n",
        "    return image\n",
        "\n",
        "\n",
        "def draw_filled_polygon(image: np.ndarray, countour: np.ndarray, color: Color) -> np.ndarray:\n",
        "    cv2.drawContours(image, [countour], 0, color.bgr_tuple, -1)\n",
        "    return image\n",
        "\n",
        "\n",
        "def draw_text(image: np.ndarray, anchor: Point, text: str, color: Color, thickness: int = 2) -> np.ndarray:\n",
        "    cv2.putText(image, text, anchor.int_xy_tuple, cv2.FONT_HERSHEY_SIMPLEX, 0.7, color.bgr_tuple, thickness, 2, False)\n",
        "    return image\n",
        "\n",
        "\n",
        "def draw_ellipse(image: np.ndarray, rect: Rect, color: Color, thickness: int = 2) -> np.ndarray:\n",
        "    cv2.ellipse(\n",
        "        image,\n",
        "        center=rect.bottom_center.int_xy_tuple,\n",
        "        axes=(int(rect.width), int(0.35 * rect.width)),\n",
        "        angle=0.0,\n",
        "        startAngle=-45,\n",
        "        endAngle=235,\n",
        "        color=color.bgr_tuple,\n",
        "        thickness=thickness,\n",
        "        lineType=cv2.LINE_4\n",
        "    )\n",
        "    return image\n",
        "\n",
        "\n",
        "# base annotator\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class BaseAnnotator:\n",
        "    colors: List[Color]\n",
        "    thickness: int\n",
        "\n",
        "    def annotate(self, image: np.ndarray, detections: List[Detection]) -> np.ndarray:\n",
        "        annotated_image = image.copy()\n",
        "        for detection in detections:\n",
        "            annotated_image = draw_ellipse(\n",
        "                image=image,\n",
        "                rect=detection.rect,\n",
        "                color=self.colors[detection.class_id],\n",
        "                thickness=self.thickness\n",
        "            )\n",
        "        return annotated_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvoYej_INhAB"
      },
      "outputs": [],
      "source": [
        "# white\n",
        "BALL_COLOR_HEX = \"#FFFFFF\"\n",
        "BALL_COLOR = Color.from_hex_string(BALL_COLOR_HEX)\n",
        "\n",
        "# red\n",
        "GOALKEEPER_COLOR_HEX = \"#850101\"\n",
        "GOALKEEPER_COLOR = Color.from_hex_string(GOALKEEPER_COLOR_HEX)\n",
        "\n",
        "# green\n",
        "PLAYER_COLOR_HEX = \"#00D4BB\"\n",
        "PLAYER_COLOR = Color.from_hex_string(PLAYER_COLOR_HEX)\n",
        "\n",
        "# yellow\n",
        "REFEREE_COLOR_HEX = \"#FFFF00\"\n",
        "REFEREE_COLOR = Color.from_hex_string(REFEREE_COLOR_HEX)\n",
        "\n",
        "COLORS = [\n",
        "    BALL_COLOR,\n",
        "    GOALKEEPER_COLOR,\n",
        "    PLAYER_COLOR,\n",
        "    REFEREE_COLOR\n",
        "]\n",
        "THICKNESS = 4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get fresh video frame generator\n",
        "frame_iterator = iter(generate_frames(video_file=SOURCE_VIDEO_PATH))"
      ],
      "metadata": {
        "id": "qpiUYnIc4g-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpD0wRkpSR6f"
      },
      "outputs": [],
      "source": [
        "# initiate annotators\n",
        "annotator = BaseAnnotator(\n",
        "    colors=COLORS,\n",
        "    thickness=THICKNESS)\n",
        "\n",
        "# acquire video frame\n",
        "frame = next(frame_iterator)\n",
        "\n",
        "# run detector\n",
        "results = model(frame, size=1280)\n",
        "detections = Detection.from_results(\n",
        "    pred=results.pred[0].cpu().numpy(),\n",
        "    names=model.names)\n",
        "\n",
        "# annotate video frame\n",
        "annotated_image = annotator.annotate(\n",
        "    image=frame,\n",
        "    detections=detections)\n",
        "\n",
        "# plot video frame\n",
        "plot_image(annotated_image, 16)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detect ball possession <a class=\"anchor\" id=\"detect-ball-possession\"></a>\n"
      ],
      "metadata": {
        "id": "-ee3fYw7AJBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to mark current ball location as well as player currently in possession with small triangle markers."
      ],
      "metadata": {
        "id": "_mNYu1MSHJE2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "keCaQCWLZh3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# black\n",
        "MARKER_CONTOUR_COLOR_HEX = \"000000\"\n",
        "MARKER_CONTOUR_COLOR = Color.from_hex_string(MARKER_CONTOUR_COLOR_HEX)\n",
        "\n",
        "# red\n",
        "PLAYER_MARKER_FILL_COLOR_HEX = \"FF0000\"\n",
        "PLAYER_MARKER_FILL_COLOR = Color.from_hex_string(PLAYER_MARKER_FILL_COLOR_HEX)\n",
        "\n",
        "# green\n",
        "BALL_MERKER_FILL_COLOR_HEX = \"00FF00\"\n",
        "BALL_MARKER_FILL_COLOR = Color.from_hex_string(BALL_MERKER_FILL_COLOR_HEX)\n",
        "\n",
        "MARKER_CONTOUR_THICKNESS = 2\n",
        "MARKER_WIDTH = 20\n",
        "MARKER_HEIGHT = 20\n",
        "MARKER_MARGIN = 10\n",
        "\n",
        "# distance in pixels from the player's bounding box where we consider the ball is in his possession\n",
        "PLAYER_IN_POSSESSION_PROXIMITY = 30"
      ],
      "metadata": {
        "id": "-J7lHOwWAvia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# calculates coordinates of possession marker\n",
        "def calculate_marker(anchor: Point) -> np.ndarray:\n",
        "    x, y = anchor.int_xy_tuple\n",
        "    return(np.array([\n",
        "        [x - MARKER_WIDTH // 2, y - MARKER_HEIGHT - MARKER_MARGIN],\n",
        "        [x, y - MARKER_MARGIN],\n",
        "        [x + MARKER_WIDTH // 2, y - MARKER_HEIGHT - MARKER_MARGIN]\n",
        "    ]))\n",
        "\n",
        "\n",
        "# draw single possession marker\n",
        "def draw_marker(image: np.ndarray, anchor: Point, color: Color) -> np.ndarray:\n",
        "    possession_marker_countour = calculate_marker(anchor=anchor)\n",
        "    image = draw_filled_polygon(\n",
        "        image=image,\n",
        "        countour=possession_marker_countour,\n",
        "        color=color)\n",
        "    image = draw_polygon(\n",
        "        image=image,\n",
        "        countour=possession_marker_countour,\n",
        "        color=MARKER_CONTOUR_COLOR,\n",
        "        thickness=MARKER_CONTOUR_THICKNESS)\n",
        "    return image\n",
        "\n",
        "\n",
        "# dedicated annotator to draw possession markers on video frames\n",
        "@dataclass\n",
        "class MarkerAnntator:\n",
        "\n",
        "    color: Color\n",
        "\n",
        "    def annotate(self, image: np.ndarray, detections: List[Detection]) -> np.ndarray:\n",
        "        annotated_image = image.copy()\n",
        "        for detection in detections:\n",
        "            annotated_image = draw_marker(\n",
        "                image=image,\n",
        "                anchor=detection.rect.top_center,\n",
        "                color=self.color)\n",
        "        return annotated_image"
      ],
      "metadata": {
        "id": "JH5AkurLCDO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "\n",
        "# resolves which player is currently in ball possession based on player-ball proximity\n",
        "def get_player_in_possession(\n",
        "    player_detections: List[Detection],\n",
        "    ball_detections: List[Detection],\n",
        "    proximity: int\n",
        ") -> Optional[Detection]:\n",
        "    if len(ball_detections) != 1:\n",
        "        return None\n",
        "    ball_detection = ball_detections[0]\n",
        "    for player_detection in player_detections:\n",
        "        if player_detection.rect.pad(proximity).contains_point(point=ball_detection.rect.center):\n",
        "            return player_detection"
      ],
      "metadata": {
        "id": "28XZOT4eHqhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single frame"
      ],
      "metadata": {
        "id": "Wl7Xz5khZbmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initiate annotators\n",
        "ball_marker_annotator = MarkerAnntator(color=BALL_MARKER_FILL_COLOR)\n",
        "player_marker_annotator = MarkerAnntator(color=PLAYER_MARKER_FILL_COLOR)\n",
        "\n",
        "# acquire video frame\n",
        "frame = next(frame_iterator)\n",
        "\n",
        "# run detector\n",
        "results = model(frame, size=1280)\n",
        "detections = Detection.from_results(\n",
        "    pred=results.pred[0].cpu().numpy(),\n",
        "    names=model.names)\n",
        "\n",
        "# postprocess results\n",
        "ball_detections = filter_detections_by_class(detections=detections, class_name=\"ball\")\n",
        "player_detections = filter_detections_by_class(detections=detections, class_name=\"player\")\n",
        "player_in_possession_detection = get_player_in_possession(\n",
        "    player_detections=player_detections,\n",
        "    ball_detections=ball_detections,\n",
        "    proximity=PLAYER_IN_POSSESSION_PROXIMITY)\n",
        "\n",
        "# annotate video frame\n",
        "annotated_image = frame.copy()\n",
        "annotated_image = ball_marker_annotator.annotate(\n",
        "    image=annotated_image,\n",
        "    detections=ball_detections)\n",
        "annotated_image = player_marker_annotator.annotate(\n",
        "    image=annotated_image,\n",
        "    detections=[player_in_possession_detection] if player_in_possession_detection else [])\n",
        "\n",
        "# plot video frame\n",
        "plot_image(annotated_image, 16)"
      ],
      "metadata": {
        "id": "TUYdBNp2Gj6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full video"
      ],
      "metadata": {
        "id": "y8HCBG9gZnDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# settings\n",
        "SOURCE_VIDEO_PATH = f\"{HOME}/clips/08fd33_4.mp4\"\n",
        "TARGET_VIDEO_PATH = f\"{HOME}/ball-possession/8fd33_4.mp4\""
      ],
      "metadata": {
        "id": "xPG2L_NyaCMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "import cv2\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "usage example:\n",
        "\n",
        "video_config = VideoConfig(\n",
        "    fps=30,\n",
        "    width=1920,\n",
        "    height=1080)\n",
        "video_writer = get_video_writer(\n",
        "    target_video_path=TARGET_VIDEO_PATH,\n",
        "    video_config=video_config)\n",
        "\n",
        "for frame in frames:\n",
        "    ...\n",
        "    video_writer.write(frame)\n",
        "\n",
        "video_writer.release()\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# stores information about output video file, width and height of the frame must be equal to input video\n",
        "@dataclass(frozen=True)\n",
        "class VideoConfig:\n",
        "    fps: float\n",
        "    width: int\n",
        "    height: int\n",
        "\n",
        "\n",
        "# create cv2.VideoWriter object that we can use to save output video\n",
        "def get_video_writer(target_video_path: str, video_config: VideoConfig) -> cv2.VideoWriter:\n",
        "    video_target_dir = os.path.dirname(os.path.abspath(target_video_path))\n",
        "    os.makedirs(video_target_dir, exist_ok=True)\n",
        "    return cv2.VideoWriter(\n",
        "        target_video_path,\n",
        "        fourcc=cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
        "        fps=video_config.fps,\n",
        "        frameSize=(video_config.width, video_config.height),\n",
        "        isColor=True\n",
        "    )"
      ],
      "metadata": {
        "id": "0ZordbZHZqIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "# initiate video writer\n",
        "video_config = VideoConfig(\n",
        "    fps=30,\n",
        "    width=1920,\n",
        "    height=1080)\n",
        "video_writer = get_video_writer(\n",
        "    target_video_path=TARGET_VIDEO_PATH,\n",
        "    video_config=video_config)\n",
        "\n",
        "# get fresh video frame generator\n",
        "frame_iterator = iter(generate_frames(video_file=SOURCE_VIDEO_PATH))\n",
        "\n",
        "# initiate annotators\n",
        "ball_marker_annotator = MarkerAnntator(color=BALL_MARKER_FILL_COLOR)\n",
        "player_marker_annotator = MarkerAnntator(color=PLAYER_MARKER_FILL_COLOR)\n",
        "\n",
        "# loop over frames\n",
        "for frame in tqdm(frame_iterator, total=750):\n",
        "\n",
        "    # run detector\n",
        "    results = model(frame, size=1280)\n",
        "    detections = Detection.from_results(\n",
        "        pred=results.pred[0].cpu().numpy(),\n",
        "        names=model.names)\n",
        "\n",
        "    # postprocess results\n",
        "    ball_detections = filter_detections_by_class(detections=detections, class_name=\"ball\")\n",
        "    goalkeeper_detections = filter_detections_by_class(detections=detections, class_name=\"goalkeeper\")\n",
        "    player_detections = filter_detections_by_class(detections=detections, class_name=\"player\") + goalkeeper_detections\n",
        "    player_in_possession_detection = get_player_in_possession(\n",
        "        player_detections=player_detections,\n",
        "        ball_detections=ball_detections,\n",
        "        proximity=PLAYER_IN_POSSESSION_PROXIMITY)\n",
        "\n",
        "    # annotate video frame\n",
        "    annotated_image = frame.copy()\n",
        "    annotated_image = ball_marker_annotator.annotate(\n",
        "        image=annotated_image,\n",
        "        detections=ball_detections)\n",
        "    annotated_image = player_marker_annotator.annotate(\n",
        "        image=annotated_image,\n",
        "        detections=[player_in_possession_detection] if player_in_possession_detection else [])\n",
        "\n",
        "    # save video frame\n",
        "    video_writer.write(annotated_image)\n",
        "\n",
        "# close output video\n",
        "video_writer.release()"
      ],
      "metadata": {
        "id": "8REr74fValXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kk15z3SIvAM"
      },
      "source": [
        "## Full video tracking <a class=\"anchor\" id=\"full-video-tracking\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# settings\n",
        "SOURCE_VIDEO_PATH = f\"{HOME}/clips/08fd33_4.mp4\"\n",
        "TARGET_VIDEO_PATH = f\"{HOME}/tracking/8fd33_4.mp4\""
      ],
      "metadata": {
        "id": "7xSEhGo7Jxot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\"\"\"\n",
        "BYTETracker does not assign tracker_id to existing bounding boxes but rather\n",
        "predicts the next bounding box position based on previous one. Therefore, we\n",
        "need to find a way to match our bounding boxes with predictions.\n",
        "\n",
        "usage example:\n",
        "\n",
        "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
        "for frame in frames:\n",
        "    ...\n",
        "    results = model(frame, size=1280)\n",
        "    detections = Detection.from_results(\n",
        "        pred=results.pred[0].cpu().numpy(),\n",
        "        names=model.names)\n",
        "    ...\n",
        "    tracks = byte_tracker.update(\n",
        "        output_results=detections2boxes(detections=detections),\n",
        "        img_info=frame.shape,\n",
        "        img_size=frame.shape)\n",
        "    detections = match_detections_with_tracks(detections=detections, tracks=tracks)\n",
        "\"\"\"\n",
        "\n",
        "# converts List[Detection] into format that can be consumed by match_detections_with_tracks function\n",
        "def detections2boxes(detections: List[Detection], with_confidence: bool = True) -> np.ndarray:\n",
        "    return np.array([\n",
        "        [\n",
        "            detection.rect.top_left.x,\n",
        "            detection.rect.top_left.y,\n",
        "            detection.rect.bottom_right.x,\n",
        "            detection.rect.bottom_right.y,\n",
        "            detection.confidence\n",
        "        ] if with_confidence else [\n",
        "            detection.rect.top_left.x,\n",
        "            detection.rect.top_left.y,\n",
        "            detection.rect.bottom_right.x,\n",
        "            detection.rect.bottom_right.y\n",
        "        ]\n",
        "        for detection\n",
        "        in detections\n",
        "    ], dtype=float)\n",
        "\n",
        "\n",
        "# converts List[STrack] into format that can be consumed by match_detections_with_tracks function\n",
        "def tracks2boxes(tracks: List[STrack]) -> np.ndarray:\n",
        "    return np.array([\n",
        "        track.tlbr\n",
        "        for track\n",
        "        in tracks\n",
        "    ], dtype=float)\n",
        "\n",
        "\n",
        "# matches our bounding boxes with predictions\n",
        "def match_detections_with_tracks(\n",
        "    detections: List[Detection],\n",
        "    tracks: List[STrack]\n",
        ") -> List[Detection]:\n",
        "    detection_boxes = detections2boxes(detections=detections, with_confidence=False)\n",
        "    tracks_boxes = tracks2boxes(tracks=tracks)\n",
        "    iou = box_iou_batch(tracks_boxes, detection_boxes)\n",
        "    track2detection = np.argmax(iou, axis=1)\n",
        "\n",
        "    for tracker_index, detection_index in enumerate(track2detection):\n",
        "        if iou[tracker_index, detection_index] != 0:\n",
        "            detections[detection_index].tracker_id = tracks[tracker_index].track_id\n",
        "    return detections"
      ],
      "metadata": {
        "id": "7wFkxJQrXokI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text annotator to display tracker_id\n",
        "@dataclass\n",
        "class TextAnnotator:\n",
        "    background_color: Color\n",
        "    text_color: Color\n",
        "    text_thickness: int\n",
        "\n",
        "    def annotate(self, image: np.ndarray, detections: List[Detection]) -> np.ndarray:\n",
        "        annotated_image = image.copy()\n",
        "        for detection in detections:\n",
        "            # if tracker_id is not assigned skip annotation\n",
        "            if detection.tracker_id is None:\n",
        "                continue\n",
        "\n",
        "            # calculate text dimensions\n",
        "            size, _ = cv2.getTextSize(\n",
        "                str(detection.tracker_id),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.7,\n",
        "                thickness=self.text_thickness)\n",
        "            width, height = size\n",
        "\n",
        "            # calculate text background position\n",
        "            center_x, center_y = detection.rect.bottom_center.int_xy_tuple\n",
        "            x = center_x - width // 2\n",
        "            y = center_y - height // 2 + 10\n",
        "\n",
        "            # draw background\n",
        "            annotated_image = draw_filled_rect(\n",
        "                image=annotated_image,\n",
        "                rect=Rect(x=x, y=y, width=width, height=height).pad(padding=5),\n",
        "                color=self.background_color)\n",
        "\n",
        "            # draw text\n",
        "            annotated_image = draw_text(\n",
        "                image=annotated_image,\n",
        "                anchor=Point(x=x, y=y + height),\n",
        "                text=str(detection.tracker_id),\n",
        "                color=self.text_color,\n",
        "                thickness=self.text_thickness)\n",
        "        return annotated_image"
      ],
      "metadata": {
        "id": "Hmqn7yL81KLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# initiate video writer\n",
        "video_config = VideoConfig(\n",
        "    fps=30,\n",
        "    width=1920,\n",
        "    height=1080)\n",
        "video_writer = get_video_writer(\n",
        "    target_video_path=TARGET_VIDEO_PATH,\n",
        "    video_config=video_config)\n",
        "\n",
        "# get fresh video frame generator\n",
        "frame_iterator = iter(generate_frames(video_file=SOURCE_VIDEO_PATH))\n",
        "\n",
        "# initiate annotators\n",
        "text_annotator = TextAnnotator(background_color=Color(255, 255, 255), text_color=Color(0, 0, 0), text_thickness=2)\n",
        "\n",
        "# initiate tracker\n",
        "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
        "\n",
        "# loop over frames\n",
        "for frame in tqdm(frame_iterator, total=750):\n",
        "\n",
        "    # run detector\n",
        "    results = model(frame, size=1280)\n",
        "    detections = Detection.from_results(\n",
        "        pred=results.pred[0].cpu().numpy(),\n",
        "        names=model.names)\n",
        "\n",
        "    # postprocess results\n",
        "    goalkeeper_detections = filter_detections_by_class(detections=detections, class_name=\"goalkeeper\")\n",
        "    player_detections = filter_detections_by_class(detections=detections, class_name=\"player\")\n",
        "    player_detections = player_detections + goalkeeper_detections\n",
        "\n",
        "    # track players\n",
        "    tracks = byte_tracker.update(\n",
        "        output_results=detections2boxes(detections=player_detections),\n",
        "        img_info=frame.shape,\n",
        "        img_size=frame.shape\n",
        "    )\n",
        "    player_detections = match_detections_with_tracks(detections=player_detections, tracks=tracks)\n",
        "\n",
        "    # annotate video frame\n",
        "    annotated_image = frame.copy()\n",
        "    annotated_image = text_annotator.annotate(\n",
        "        image=annotated_image,\n",
        "        detections=player_detections)\n",
        "\n",
        "    # save video frame\n",
        "    video_writer.write(annotated_image)\n",
        "\n",
        "# close output video\n",
        "video_writer.release()"
      ],
      "metadata": {
        "id": "uAEdmxpf17NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Put everything together <a class=\"anchor\" id=\"put-everything-together\"></a>"
      ],
      "metadata": {
        "id": "Zgsvgved-1xQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# settings\n",
        "# SOURCE_VIDEO_PATH = f\"{HOME}/clips/0a2d9b_0.mp4\"\n",
        "# TARGET_VIDEO_PATH = f\"{HOME}/final/0a2d9b_0.mp4\"\n",
        "\n",
        "SOURCE_VIDEO_PATH = f\"{HOME}/clips/08fd33_4.mp4\"\n",
        "TARGET_VIDEO_PATH = f\"{HOME}/final/08fd33_4.mp4\""
      ],
      "metadata": {
        "id": "jYM4lks7VzOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SELyRdNDIsS-"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# initiate video writer\n",
        "video_config = VideoConfig(\n",
        "    fps=30,\n",
        "    width=1920,\n",
        "    height=1080)\n",
        "video_writer = get_video_writer(\n",
        "    target_video_path=TARGET_VIDEO_PATH,\n",
        "    video_config=video_config)\n",
        "\n",
        "# get fresh video frame generator\n",
        "frame_iterator = iter(generate_frames(video_file=SOURCE_VIDEO_PATH))\n",
        "\n",
        "# initiate annotators\n",
        "base_annotator = BaseAnnotator(\n",
        "    colors=[\n",
        "        BALL_COLOR,\n",
        "        PLAYER_COLOR,\n",
        "        PLAYER_COLOR,\n",
        "        REFEREE_COLOR\n",
        "    ],\n",
        "    thickness=THICKNESS)\n",
        "\n",
        "player_goalkeeper_text_annotator = TextAnnotator(\n",
        "    PLAYER_COLOR, text_color=Color(255, 255, 255), text_thickness=2)\n",
        "referee_text_annotator = TextAnnotator(\n",
        "    REFEREE_COLOR, text_color=Color(0, 0, 0), text_thickness=2)\n",
        "\n",
        "ball_marker_annotator = MarkerAnntator(\n",
        "    color=BALL_MARKER_FILL_COLOR)\n",
        "player_in_possession_marker_annotator = MarkerAnntator(\n",
        "    color=PLAYER_MARKER_FILL_COLOR)\n",
        "\n",
        "\n",
        "# initiate tracker\n",
        "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
        "\n",
        "# loop over frames\n",
        "for frame in tqdm(frame_iterator, total=750):\n",
        "\n",
        "    # run detector\n",
        "    results = model(frame, size=1280)\n",
        "    detections = Detection.from_results(\n",
        "        pred=results.pred[0].cpu().numpy(),\n",
        "        names=model.names)\n",
        "\n",
        "    # filter detections by class\n",
        "    ball_detections = filter_detections_by_class(detections=detections, class_name=\"ball\")\n",
        "    referee_detections = filter_detections_by_class(detections=detections, class_name=\"referee\")\n",
        "    goalkeeper_detections = filter_detections_by_class(detections=detections, class_name=\"goalkeeper\")\n",
        "    player_detections = filter_detections_by_class(detections=detections, class_name=\"player\")\n",
        "\n",
        "    player_goalkeeper_detections = player_detections + goalkeeper_detections\n",
        "    tracked_detections = player_detections + goalkeeper_detections + referee_detections\n",
        "\n",
        "    # calculate player in possession\n",
        "    player_in_possession_detection = get_player_in_possession(\n",
        "        player_detections=player_goalkeeper_detections,\n",
        "        ball_detections=ball_detections,\n",
        "        proximity=PLAYER_IN_POSSESSION_PROXIMITY)\n",
        "\n",
        "    # track\n",
        "    tracks = byte_tracker.update(\n",
        "        output_results=detections2boxes(detections=tracked_detections),\n",
        "        img_info=frame.shape,\n",
        "        img_size=frame.shape\n",
        "    )\n",
        "    tracked_detections = match_detections_with_tracks(detections=tracked_detections, tracks=tracks)\n",
        "\n",
        "    tracked_referee_detections = filter_detections_by_class(detections=tracked_detections, class_name=\"referee\")\n",
        "    tracked_goalkeeper_detections = filter_detections_by_class(detections=tracked_detections, class_name=\"goalkeeper\")\n",
        "    tracked_player_detections = filter_detections_by_class(detections=tracked_detections, class_name=\"player\")\n",
        "\n",
        "    # annotate video frame\n",
        "    annotated_image = frame.copy()\n",
        "    annotated_image = base_annotator.annotate(\n",
        "        image=annotated_image,\n",
        "        detections=tracked_detections)\n",
        "\n",
        "    annotated_image = player_goalkeeper_text_annotator.annotate(\n",
        "        image=annotated_image,\n",
        "        detections=tracked_goalkeeper_detections + tracked_player_detections)\n",
        "    annotated_image = referee_text_annotator.annotate(\n",
        "        image=annotated_image,\n",
        "        detections=tracked_referee_detections)\n",
        "\n",
        "    annotated_image = ball_marker_annotator.annotate(\n",
        "        image=annotated_image,\n",
        "        detections=ball_detections)\n",
        "    annotated_image = player_marker_annotator.annotate(\n",
        "        image=annotated_image,\n",
        "        detections=[player_in_possession_detection] if player_in_possession_detection else [])\n",
        "\n",
        "    # save video frame\n",
        "    video_writer.write(annotated_image)\n",
        "\n",
        "# close output video\n",
        "video_writer.release()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "nZvayA0p2wKs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}